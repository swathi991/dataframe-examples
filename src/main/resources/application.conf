conf {

    s3_conf {
        access_key = "AKIA2BB4X4ETFFZA5JW5"
        secret_access_key = "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"
        s3_bucket = "swat-spark"
    }

    mysql_conf {
        hostname = "testdb-spark.cadeezt9xs0a.eu-west-1.rds.amazonaws.com"
        port = "3306"
        database = "testdb-spark"
        username = "master"
        password = "$WAths99"
    }

    sftp_conf {
        hostname = "ubuntu@ec2-34-241-44-197.eu-west-1.compute.amazonaws.com"
        port = "22"
        username = "ubuntu"
        pem = "C:\Users\679937\IdeaProjects\ubantu.pem"
        filetype = "csv"
        delimiter = "|"
        directory = "/home/ubuntu/data"
    }

    mongodb_config {
        input.uri = "mongodb://13.234.48.111"
        output.uri = "mongodb://13.234.48.111"
        input.database = "school"
        database = "school"
        collection = "students"
    }

    redshift_conf = {
        host = "test.abc.eu-west-1.redshift.amazonaws.com"
        port = "5439"
        database = "test_db"
        username = "master"
        password = "Temp-1234"
        filetype = "csv"
        delimiter = "|"
    }

    spark_sql_demo = {
        agg_demo = """
            select
                AccountNumber,
                UniqueTransactionDescriptions,
                sort_array(UniqueTransactionDescriptions, false) as OrderedUniqueTransactionDescriptions,
                size(UniqueTransactionDescriptions) as CountOfUniqueTransactionTypes,
                array_contains(UniqueTransactionDescriptions, 'Movies') as WentToMovies
            from
                agg_finances
            """

        case_when_demo = """
            select
                company,
                employee.firstName as firstName,
                case
                    when company = 'FamilyCo' then 'Premium'
                    when company = 'OldCo' then 'Legacy'
                    else 'Standard'
                end as Tier
            from
                employees
            """

    }
}